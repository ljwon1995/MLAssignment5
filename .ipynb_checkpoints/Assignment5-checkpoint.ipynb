{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "train_data_path = './horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1027, shuffle=False, num_workers=1)  \n",
    "\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "trainList = list()\n",
    "validList = list()\n",
    "trainLabelList = list()\n",
    "validLabelList = list()\n",
    "\n",
    "for i, data in enumerate(trainloader):\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    # change inputs to matrix 10000*batch_size\n",
    "    for bat_idx in range(batch_size):\n",
    "\n",
    "        targMat = inputs[bat_idx][0]\n",
    "\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat, colVec), axis = 1)         \n",
    "\n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    trainList.append(batMat)\n",
    "    trainLabelList.append(labels)\n",
    "    \n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "     # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "    # Change Inputs to matrix 10000*batch_size\n",
    "\n",
    "    for bat_idx in range(batch_size):\n",
    "        targMat = inputs[bat_idx][0]\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat,colVec), axis = 1)\n",
    "        \n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    validList.append(batMat)\n",
    "    validLabelList.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    result = ((np.exp(z) - np.exp(-z)) / (np.exp(z)+np.exp(-z))) \n",
    "    return result\n",
    "\n",
    "def relu(z):\n",
    "    return z * (z > 0)\n",
    "\n",
    "def lrelu(z):\n",
    "    alpha = 0.01\n",
    "    x1 = z * (z > 0)\n",
    "    x2 = z * (z<=0) * alpha\n",
    "    return x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## #Initialize Coefs\n",
    "\n",
    "\n",
    "sigmoid_w_0 = np.zeros((1,10001), dtype = float)\n",
    "a = np.ones((1,10001), dtype = float)\n",
    "sigmoid_w_0 =np.concatenate((sigmoid_w_0, a), axis = 0)\n",
    "a = 2 * np.ones((1,10001), dtype = float)\n",
    "sigmoid_w_0 =np.concatenate((sigmoid_w_0, a), axis = 0)\n",
    "a = 3 * np.ones((1,10001), dtype = float)\n",
    "sigmoid_w_0 =np.concatenate((sigmoid_w_0, a), axis = 0)\n",
    "\n",
    "\n",
    "sigmoid_w_1 = np.array([[0,0,0,0],\n",
    "              [ 1, 1, 1, 1],\n",
    "              [ 2, 2, 2, 2]], dtype = float)\n",
    "\n",
    "sigmoid_w_2 = np.array([[0.0, 0.0, 0.0]])\n",
    "\n",
    "\n",
    "\n",
    "tanh_w_0 = np.zeros((1,10001), dtype = float)\n",
    "a = np.ones((1,10001), dtype = float) * 0.01\n",
    "tanh_w_0 =np.concatenate((tanh_w_0, a), axis = 0)\n",
    "a = -2 * np.ones((1,10001), dtype = float) * 0.01\n",
    "tanh_w_0 =np.concatenate((tanh_w_0, a), axis = 0)\n",
    "a = 3 * np.ones((1,10001), dtype = float) * 0.01\n",
    "tanh_w_0 =np.concatenate((tanh_w_0, a), axis = 0)\n",
    "\n",
    "\n",
    "tanh_w_1 = np.array([[0,0,0,0],\n",
    "              [-0.01,-0.01,-0.01,-0.01],\n",
    "              [0.02,0.02,0.02,0.02]], dtype = float)\n",
    "\n",
    "tanh_w_2 = np.array([[0.1, 0.1, 0.1]])\n",
    "\n",
    "\n",
    "\n",
    "relu_w_0 = np.zeros((1,10001), dtype = float)\n",
    "a = np.ones((1,10001), dtype = float) * 0.001\n",
    "relu_w_0 =np.concatenate((relu_w_0, a), axis = 0)\n",
    "a = 2 * np.ones((1,10001), dtype = float) * 0.001\n",
    "relu_w_0 =np.concatenate((relu_w_0, a), axis = 0)\n",
    "a = 3 * np.ones((1,10001), dtype = float) * 0.001\n",
    "relu_w_0 =np.concatenate((relu_w_0, a), axis = 0)\n",
    "\n",
    "\n",
    "relu_w_1 = np.array([[0,0,0,0],\n",
    "              [0.001,0.001,0.001,0.001],\n",
    "              [0.002,0.002,0.002,0.002]], dtype = float)\n",
    "\n",
    "relu_w_2 = np.zeros((1, 3), dtype = float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lrelu_w_0 = np.zeros((1,10001), dtype = float)\n",
    "a = np.ones((1,10001), dtype = float) * 0.001\n",
    "lrelu_w_0 =np.concatenate((lrelu_w_0, a), axis = 0)\n",
    "a = 2 * np.ones((1,10001), dtype = float) * 0.001\n",
    "lrelu_w_0 =np.concatenate((lrelu_w_0, a), axis = 0)\n",
    "a = 3 * np.ones((1,10001), dtype = float) * 0.001\n",
    "lrelu_w_0 =np.concatenate((lrelu_w_0, a), axis = 0)\n",
    "\n",
    "\n",
    "lrelu_w_1 = np.array([[0,0,0,0],\n",
    "              [0.001,0.001,0.001,0.001],\n",
    "              [0.002,0.002,0.002,0.002]], dtype = float)\n",
    "\n",
    "lrelu_w_2 = np.zeros((1, 3), dtype = float)\n",
    "\n",
    "\n",
    "#set DataNum\n",
    "totalTrainDataNum = len(trainloader.dataset)\n",
    "totalValidDataNum  = len(valloader.dataset)\n",
    "\n",
    "#Set Learning Rate\n",
    "sigmoidLrnRate = 0.01\n",
    "tanhLrnRate = 0.001\n",
    "reluLrnRate = 0.002\n",
    "lreluLrnRate = 0.002\n",
    "\n",
    "sigmoidMaxAcc = 0\n",
    "tanhMaxAcc = 0\n",
    "reluMaxAcc = 0\n",
    "lreluMaxAcc = 0\n",
    "\n",
    "sigmoidMinLoss = 1\n",
    "tanhMinLoss = 1\n",
    "reluMinLoss = 1\n",
    "lreluMinLoss = 1\n",
    "\n",
    "\n",
    "# Set Loss Lists\n",
    "sigmoidLrnLoss = list()\n",
    "sigmoidValLoss = list()\n",
    "\n",
    "tanhLrnLoss = list()\n",
    "tanhValLoss = list()\n",
    "\n",
    "reluLrnLoss = list()\n",
    "reluValLoss = list()\n",
    "\n",
    "lreluLrnLoss = list()\n",
    "lreluValLoss = list()\n",
    "\n",
    "# Set Accurate Lists\n",
    "sigmoidLrnAcc = list()\n",
    "sigmoidValAcc = list()\n",
    "\n",
    "tanhLrnAcc = list()\n",
    "tanhValAcc = list()\n",
    "\n",
    "reluLrnAcc = list()\n",
    "reluValAcc = list()\n",
    "\n",
    "lreluLrnAcc = list()\n",
    "lreluValAcc = list()\n",
    "\n",
    "epoch = -1\n",
    "sigmoidLrnAccRate = 0\n",
    "tanhLrnAccRate = 0\n",
    "reluLrnAccRate = 0\n",
    "lreluLrnAccRate = 0\n",
    "\n",
    "\n",
    "\n",
    "s = time.time()\n",
    "#while(sigmoidLrnAccRate < 1  or tanhLrnAccRate < 1 or reluLrnAccRate < 1 or lreluLrnAccRate < 1):\n",
    "while(epoch < 50000):\n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "    #Set Sum of Cor to 0\n",
    "    sigmoidCor = 0\n",
    "    tanhCor = 0\n",
    "    reluCor = 0\n",
    "    lreluCor = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sigmoid_a_0 = trainList[0]\n",
    "    tanh_a_0 = trainList[0]\n",
    "    relu_a_0 = trainList[0]\n",
    "    lrelu_a_0 = trainList[0]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    batch_size = sigmoid_a_0.shape[1]\n",
    "\n",
    "    # Start Regression Calculation\n",
    "    sigmoid_z_0 = np.dot(sigmoid_w_0, sigmoid_a_0)\n",
    "    tanh_z_0 = np.dot(tanh_w_0, tanh_a_0)\n",
    "    relu_z_0 = np.dot(relu_w_0, relu_a_0)\n",
    "    lrelu_z_0 = np.dot(lrelu_w_0, lrelu_a_0)\n",
    "  \n",
    "    \n",
    "    sigmoid_a_1 = sigmoid(sigmoid_z_0)\n",
    "    tanh_a_1 = tanh(tanh_z_0)\n",
    "    relu_a_1 = relu(relu_z_0)\n",
    "    lrelu_a_1 = lrelu(lrelu_z_0)\n",
    "\n",
    "\n",
    "\n",
    "    sigmoid_z_1 = np.dot(sigmoid_w_1, sigmoid_a_1)\n",
    "    tanh_z_1 = np.dot(tanh_w_1, tanh_a_1)\n",
    "    relu_z_1 = np.dot(relu_w_1, relu_a_1)\n",
    "    lrelu_z_1 = np.dot(lrelu_w_1, lrelu_a_1)\n",
    "    \n",
    "    sigmoid_a_2 = sigmoid(sigmoid_z_1)\n",
    "    tanh_a_2 = tanh(tanh_z_1)\n",
    "    relu_a_2 = relu(relu_z_1)\n",
    "    lrelu_a_2 = lrelu(lrelu_z_1)\n",
    "\n",
    "    \n",
    "    sigmoid_z_2 = np.dot(sigmoid_w_2, sigmoid_a_2)\n",
    "    tanh_z_2 = np.dot(tanh_w_2, tanh_a_2)\n",
    "    relu_z_2 = np.dot(relu_w_2, relu_a_2)\n",
    "    lrelu_z_2 = np.dot(lrelu_w_2, lrelu_a_2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    sigmoid_a_3 = sigmoid(sigmoid_z_2)\n",
    "    tanh_a_3 = sigmoid(tanh_z_2)\n",
    "    relu_a_3 = sigmoid(relu_z_2)\n",
    "    lrelu_a_3 = sigmoid(lrelu_z_2)\n",
    "    \n",
    "\n",
    "  #  print(relu_a_0)\n",
    "   # print(relu_w_0)\n",
    "   # print(relu_z_0)\n",
    "    \n",
    "  #  print(relu_a_1)\n",
    "  #  print(relu_w_1)\n",
    "  #  print(relu_z_1)\n",
    "    \n",
    "  #  print(relu_a_2)\n",
    "  #  print(relu_w_2)\n",
    "  #  print(relu_z_2)\n",
    "    \n",
    "  #  print(relu_a_3)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    sigmoid_dz_2 = np.subtract(sigmoid_a_3, trainLabelList[0])\n",
    "    tanh_dz_2 = np.subtract(tanh_a_3, trainLabelList[0])\n",
    "    relu_dz_2 = np.subtract(relu_a_3, trainLabelList[0])\n",
    "    lrelu_dz_2 = np.subtract(lrelu_a_3, trainLabelList[0])\n",
    "    \n",
    "    sigmoid_dw_2 = np.dot(sigmoid_dz_2, sigmoid_a_2.T) / totalTrainDataNum\n",
    "    tanh_dw_2 = np.dot(tanh_dz_2, tanh_a_2.T) / totalTrainDataNum\n",
    "    relu_dw_2 = np.dot(relu_dz_2, relu_a_2.T) / totalTrainDataNum\n",
    "    lrelu_dw_2 = np.dot(lrelu_dz_2, lrelu_a_2.T) / totalTrainDataNum\n",
    "    \n",
    "   \n",
    "    \n",
    "    sigmoid_dz_1 = np.dot(sigmoid_w_2.T, sigmoid_dz_2) * sigmoid_a_2 * (1-sigmoid_a_2)\n",
    "    tanh_dz_1 = np.dot(tanh_w_2.T, tanh_dz_2) * (1 - (tanh_a_2 * tanh_a_2))\n",
    "    relu_dz_1 = np.dot(relu_w_2.T, relu_dz_2) * (1 * (relu_z_1 > 0))\n",
    "    lrelu_dz_1 = np.dot(lrelu_w_2.T, lrelu_dz_2) * ((1 * (lrelu_z_1 > 0)) + 0.01 * (lrelu_z_1 <= 0))\n",
    "    \n",
    "    sigmoid_dw_1 = np.dot(sigmoid_dz_1, sigmoid_a_1.T) / totalTrainDataNum\n",
    "    tanh_dw_1 = np.dot(tanh_dz_1, tanh_a_1.T) / totalTrainDataNum\n",
    "    relu_dw_1 = np.dot(relu_dz_1, relu_a_1.T) / totalTrainDataNum\n",
    "    lrelu_dw_1 = np.dot(lrelu_dz_1, lrelu_a_1.T) / totalTrainDataNum\n",
    "    \n",
    "\n",
    "    sigmoid_dz_0 = np.dot(sigmoid_w_1.T, sigmoid_dz_1) * sigmoid_a_1 * (1-sigmoid_a_1)\n",
    "    tanh_dz_0 = np.dot(tanh_w_1.T, tanh_dz_1) * (1 - (tanh_a_1 * tanh_a_1))\n",
    "    relu_dz_0 = np.dot(relu_w_1.T, relu_dz_1) * (1 * (relu_z_0 > 0))\n",
    "    lrelu_dz_0 = np.dot(lrelu_w_1.T, lrelu_dz_1) * ((1 * (lrelu_z_0 > 0)) + 0.01 * (lrelu_z_0 <= 0))\n",
    "    \n",
    "    \n",
    "    sigmoid_dw_0 = np.dot(sigmoid_dz_0, sigmoid_a_0.T) / totalTrainDataNum\n",
    "    tanh_dw_0 = np.dot(tanh_dz_0, tanh_a_0.T) / totalTrainDataNum\n",
    "    relu_dw_0 = np.dot(relu_dz_0, relu_a_0.T) / totalTrainDataNum\n",
    "    lrelu_dw_0 = np.dot(lrelu_dz_0, lrelu_a_0.T) / totalTrainDataNum\n",
    "    \n",
    "\n",
    "    \n",
    "    sigmoid_w_2 -= sigmoidLrnRate * sigmoid_dw_2\n",
    "    tanh_w_2 -= tanhLrnRate * tanh_dw_2\n",
    "    relu_w_2 -= reluLrnRate * relu_dw_2\n",
    "    lrelu_w_2 -= lreluLrnRate * lrelu_dw_2\n",
    "    \n",
    "    sigmoid_w_1 -= sigmoidLrnRate * sigmoid_dw_1\n",
    "    tanh_w_1 -= tanhLrnRate * tanh_dw_1\n",
    "    relu_w_1 -= reluLrnRate * relu_dw_1\n",
    "    lrelu_w_1 -= lreluLrnRate * lrelu_dw_1\n",
    "\n",
    "    sigmoid_w_0 -= sigmoidLrnRate * sigmoid_dw_0\n",
    "    tanh_w_0 -= tanhLrnRate * tanh_dw_0\n",
    "    relu_w_0 -= reluLrnRate * relu_dw_0\n",
    "    lrelu_w_0 -= lreluLrnRate * lrelu_dw_0\n",
    "    \n",
    "    \n",
    "    #Calculate Total Loss\n",
    "    sigmoid_a_3 = torch.from_numpy(sigmoid_a_3)\n",
    "    tanh_a_3 = torch.from_numpy(tanh_a_3)\n",
    "    relu_a_3 = torch.from_numpy(relu_a_3)\n",
    "    lrelu_a_3 = torch.from_numpy(lrelu_a_3)\n",
    "    \n",
    "    dLabels = trainLabelList[0].double()\n",
    "    \n",
    "    sigmoidSumL = (-(dLabels) * np.log(sigmoid_a_3) - (1-dLabels) * np.log(1- sigmoid_a_3)).sum()\n",
    "    tanhSumL = (-(dLabels) * np.log(tanh_a_3) - (1-dLabels) * np.log(1- tanh_a_3)).sum()\n",
    "    reluSumL = (-(dLabels) * np.log(relu_a_3) - (1-dLabels) * np.log(1- relu_a_3)).sum()\n",
    "    lreluSumL = (-(dLabels) * np.log(lrelu_a_3) - (1-dLabels) * np.log(1- lrelu_a_3)).sum()\n",
    "    \n",
    "    \n",
    "    sigmoidLrnLoss.append(sigmoidSumL / totalTrainDataNum)\n",
    "    tanhLrnLoss.append(tanhSumL / totalTrainDataNum)\n",
    "    reluLrnLoss.append(reluSumL / totalTrainDataNum)\n",
    "    lreluLrnLoss.append(lreluSumL / totalTrainDataNum)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "\n",
    "    for batIdx in range(batch_size):\n",
    "\n",
    "        if(sigmoid_a_3[0][batIdx] <= 0.5 and trainLabelList[0][batIdx] == 0):\n",
    "            sigmoidCor += 1\n",
    "\n",
    "        if(sigmoid_a_3[0][batIdx] > 0.5 and trainLabelList[0][batIdx] == 1):\n",
    "            sigmoidCor += 1\n",
    "        \n",
    "        if(tanh_a_3[0][batIdx] <= 0.5 and trainLabelList[0][batIdx] == 0):\n",
    "            tanhCor += 1\n",
    "\n",
    "        if(tanh_a_3[0][batIdx] > 0.5 and trainLabelList[0][batIdx] == 1):\n",
    "            tanhCor += 1\n",
    "                \n",
    "        if(relu_a_3[0][batIdx] <= 0.5 and trainLabelList[0][batIdx] == 0):\n",
    "            reluCor += 1\n",
    "\n",
    "        if(relu_a_3[0][batIdx] > 0.5 and trainLabelList[0][batIdx] == 1):\n",
    "            reluCor += 1\n",
    "            \n",
    "        if(lrelu_a_3[0][batIdx] <= 0.5 and trainLabelList[0][batIdx] == 0):\n",
    "            lreluCor += 1\n",
    "\n",
    "        if(lrelu_a_3[0][batIdx] > 0.5 and trainLabelList[0][batIdx] == 1):\n",
    "            lreluCor += 1\n",
    "            \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    \n",
    "    sigmoidLrnAccRate = sigmoidCor / totalTrainDataNum\n",
    "    tanhLrnAccRate = tanhCor / totalTrainDataNum\n",
    "    reluLrnAccRate = reluCor / totalTrainDataNum\n",
    "    lreluLrnAccRate = lreluCor / totalTrainDataNum\n",
    "    \n",
    "    sigmoidLrnAcc.append(sigmoidLrnAccRate)\n",
    "    tanhLrnAcc.append(tanhLrnAccRate)\n",
    "    reluLrnAcc.append(reluLrnAccRate)\n",
    "    lreluLrnAcc.append(lreluLrnAccRate)\n",
    "    \n",
    "\n",
    "\n",
    "    #Set Sum of Cor to 0\n",
    "    sigmoidValCor = 0\n",
    "    tanhValCor = 0\n",
    "    reluValCor = 0\n",
    "    lreluValCor = 0\n",
    "    \n",
    "\n",
    "\n",
    "    sigmoid_a_0 = validList[0]\n",
    "    tanh_a_0 = validList[0]\n",
    "    relu_a_0 = validList[0]\n",
    "    lrelu_a_0 = validList[0]\n",
    "        \n",
    "    batch_size = sigmoid_a_0.shape[1]\n",
    "\n",
    "    # Start Regression Calculation\n",
    "    sigmoid_z_0 = np.dot(sigmoid_w_0, sigmoid_a_0)\n",
    "    \n",
    "    tanh_z_0 = np.dot(tanh_w_0, tanh_a_0)\n",
    "    relu_z_0 = np.dot(relu_w_0, relu_a_0)\n",
    "    lrelu_z_0 = np.dot(lrelu_w_0, lrelu_a_0)\n",
    "    \n",
    "    sigmoid_a_1 = sigmoid(sigmoid_z_0)\n",
    "    tanh_a_1 = tanh(tanh_z_0)\n",
    "    relu_a_1 = relu(relu_z_0)\n",
    "    lrelu_a_1 = lrelu(lrelu_z_0)\n",
    "\n",
    "\n",
    "    sigmoid_z_1 = np.dot(sigmoid_w_1, sigmoid_a_1)\n",
    "    tanh_z_1 = np.dot(tanh_w_1, tanh_a_1)\n",
    "    relu_z_1 = np.dot(relu_w_1, relu_a_1)\n",
    "    lrelu_z_1 = np.dot(lrelu_w_1, lrelu_a_1)\n",
    "    \n",
    "    sigmoid_a_2 = sigmoid(sigmoid_z_1)\n",
    "    tanh_a_2 = tanh(tanh_z_1)\n",
    "    relu_a_2 = relu(relu_z_1)\n",
    "    lrelu_a_2 = lrelu(lrelu_z_1)\n",
    "    \n",
    "    sigmoid_z_2 = np.dot(sigmoid_w_2, sigmoid_a_2)\n",
    "    tanh_z_2 = np.dot(tanh_w_2, tanh_a_2)\n",
    "    relu_z_2 = np.dot(relu_w_2, relu_a_2)\n",
    "    lrelu_z_2 = np.dot(lrelu_w_2, lrelu_a_2)\n",
    "    \n",
    "    sigmoid_a_3 = sigmoid(sigmoid_z_2)\n",
    "    tanh_a_3 = sigmoid(tanh_z_2)\n",
    "    relu_a_3 = sigmoid(relu_z_2)\n",
    "    lrelu_a_3 = sigmoid(lrelu_z_2)\n",
    "    \n",
    "    #Calculate Total Loss\n",
    "    sigmoid_a_3 = torch.from_numpy(sigmoid_a_3)\n",
    "    tanh_a_3 = torch.from_numpy(tanh_a_3)\n",
    "    relu_a_3 = torch.from_numpy(relu_a_3)\n",
    "    lrelu_a_3 = torch.from_numpy(lrelu_a_3)\n",
    "    \n",
    "    dLabels = validLabelList[0].double()\n",
    "    \n",
    "    sigmoidSumL = (-(dLabels) * np.log(sigmoid_a_3) - (1-dLabels) * np.log(1- sigmoid_a_3)).sum()\n",
    "    tanhSumL = (-(dLabels) * np.log(tanh_a_3) - (1-dLabels) * np.log(1- tanh_a_3)).sum()\n",
    "    reluSumL = (-(dLabels) * np.log(relu_a_3) - (1-dLabels) * np.log(1- relu_a_3)).sum()\n",
    "    lreluSumL = (-(dLabels) * np.log(lrelu_a_3) - (1-dLabels) * np.log(1- lrelu_a_3)).sum()\n",
    "    \n",
    "    \n",
    "    sigmoidValLoss.append(sigmoidSumL / totalValidDataNum)\n",
    "    tanhValLoss.append(tanhSumL / totalValidDataNum)\n",
    "    reluValLoss.append(reluSumL / totalValidDataNum)\n",
    "    lreluValLoss.append(lreluSumL / totalValidDataNum)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "\n",
    "    for batIdx in range(batch_size):\n",
    "\n",
    "        if(sigmoid_a_3[0][batIdx] <= 0.5 and validLabelList[0][batIdx] == 0):\n",
    "            sigmoidValCor += 1\n",
    "\n",
    "        if(sigmoid_a_3[0][batIdx] > 0.5 and validLabelList[0][batIdx] == 1):\n",
    "            sigmoidValCor += 1\n",
    "        \n",
    "        if(tanh_a_3[0][batIdx] <= 0.5 and validLabelList[0][batIdx] == 0):\n",
    "            tanhValCor += 1\n",
    "\n",
    "        if(tanh_a_3[0][batIdx] > 0.5 and validLabelList[0][batIdx] == 1):\n",
    "            tanhValCor += 1\n",
    "                \n",
    "        if(relu_a_3[0][batIdx] <= 0.5 and validLabelList[0][batIdx] == 0):\n",
    "            reluValCor += 1\n",
    "\n",
    "        if(relu_a_3[0][batIdx] > 0.5 and validLabelList[0][batIdx] == 1):\n",
    "            reluValCor += 1\n",
    "            \n",
    "        if(lrelu_a_3[0][batIdx] <= 0.5 and validLabelList[0][batIdx] == 0):\n",
    "            lreluValCor += 1\n",
    "\n",
    "        if(lrelu_a_3[0][batIdx] > 0.5 and validLabelList[0][batIdx] == 1):\n",
    "            lreluValCor += 1\n",
    "            \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    \n",
    "    sigmoidValAccRate = sigmoidValCor / totalValidDataNum\n",
    "    tanhValAccRate = tanhValCor / totalValidDataNum\n",
    "    reluValAccRate = reluValCor / totalValidDataNum\n",
    "    lreluValAccRate = lreluValCor / totalValidDataNum\n",
    "    \n",
    "    sigmoidValAcc.append(sigmoidValAccRate)\n",
    "    tanhValAcc.append(tanhValAccRate)\n",
    "    reluValAcc.append(reluValAccRate)\n",
    "    lreluValAcc.append(lreluValAccRate)\n",
    "    \n",
    "    if sigmoidMaxAcc < sigmoidValAccRate:\n",
    "        sigmoidMaxAcc = sigmoidValAccRate\n",
    "        sigmoidMinLoss = sigmoidValLoss[-1]\n",
    "        \n",
    "    \n",
    "    if tanhMaxAcc < tanhValAccRate:\n",
    "        tanhMaxAcc = tanhValAccRate\n",
    "        tanhMinLoss = tanhValLoss[-1]\n",
    "        \n",
    "    if reluMaxAcc < reluValAccRate:\n",
    "        reluMaxAcc = reluValAccRate\n",
    "        reluMinLoss = reluValLoss[-1]\n",
    "        \n",
    "    if lreluMaxAcc < lreluValAccRate:\n",
    "        lreluMaxAcc = lreluValAccRate\n",
    "        lreluMinLoss = lreluValLoss[-1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    if epoch%1000 == 0:\n",
    "        print(\"-------------- epoch %6d\" % epoch, \"--------------\")\n",
    "        print(\"sigmoidLrnLoss : \", sigmoidLrnLoss[-1].item())\n",
    "        print(\"tanhLrnLoss : \", tanhLrnLoss[-1].item())\n",
    "        print(\"reluLrnLoss : \", reluLrnLoss[-1].item())\n",
    "        print(\"lreluLrnLoss : \", lreluLrnLoss[-1].item())\n",
    "        print(\"sigmoidValLoss : \", sigmoidValLoss[-1].item())\n",
    "        print(\"tanhValLoss : \", tanhValLoss[-1].item())\n",
    "        print(\"reluValLoss : \", reluValLoss[-1].item())\n",
    "        print(\"lreluValLoss : \", lreluValLoss[-1].item())\n",
    "        print(\"-------------------------------------------\")\n",
    "    '''\n",
    "    \n",
    "    \n",
    "elapsedT = time.time() - s\n",
    "h = (int)(elapsedT / 3600)\n",
    "elapsedT %= 3600\n",
    "m = (int)(elapsedT / 60)\n",
    "elapsedT %= 60\n",
    "s = elapsedT\n",
    "\n",
    "#print(\"eTime : %dh %dm %fs\" % (h, m, s)  )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,4))\n",
    "\n",
    "\n",
    "axs[0].plot(sigmoidLrnLoss, color = 'red', label = \"SigmoidTrainingLoss\")\n",
    "\n",
    "\n",
    "axs[1].plot(sigmoidValLoss, color = 'blue', label = \"SigmoidValidationLoss\")\n",
    "\n",
    "axs[0].set(ylabel = 'Loss')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Loss')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,4))\n",
    "\n",
    "\n",
    "axs[0].plot(tanhLrnLoss, color = 'red', label = \"TanhTrainingLoss\")\n",
    "\n",
    "\n",
    "axs[1].plot(tanhValLoss, color = 'blue', label = \"TanhValidationLoss\")\n",
    "\n",
    "axs[0].set(ylabel = 'Loss')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Loss')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,4))\n",
    "\n",
    "\n",
    "axs[0].plot(reluLrnLoss, color = 'red', label = \"ReLuTrainingLoss\")\n",
    "\n",
    "\n",
    "axs[1].plot(reluValLoss, color = 'blue', label = \"ReLuValidationLoss\")\n",
    "\n",
    "axs[0].set(ylabel = 'Loss')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Loss')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,4))\n",
    "\n",
    "\n",
    "axs[0].plot(lreluLrnLoss, color = 'red', label = \"LeakyReLuTrainingLoss\")\n",
    "\n",
    "\n",
    "axs[1].plot(lreluValLoss, color = 'blue', label = \"LeakyReLuValidationLoss\")\n",
    "\n",
    "axs[0].set(ylabel = 'Loss')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Loss')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,5))\n",
    "\n",
    "\n",
    "axs[0].plot(sigmoidLrnAcc, color = 'orange', label = \"SigmoidTrainingAccuracy\")\n",
    "\n",
    "\n",
    "axs[1].plot(sigmoidValAcc, color = 'green', label = \"SigmoidValidationAccuracy\")\n",
    "\n",
    "axs[0].set(ylabel = 'Accuracy')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Accuracy')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,5))\n",
    "\n",
    "\n",
    "axs[0].plot(tanhLrnAcc, color = 'orange', label = \"TanhTrainingAccuracy\")\n",
    "\n",
    "\n",
    "axs[1].plot(tanhValAcc, color = 'green', label = \"TanhValidationAccuracy\")\n",
    "\n",
    "axs[0].set(ylabel = 'Accuracy')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Accuracy')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,5))\n",
    "\n",
    "\n",
    "axs[0].plot(reluLrnAcc, color = 'orange', label = \"ReLuTrainingAccuracy\")\n",
    "\n",
    "\n",
    "axs[1].plot(reluValAcc, color = 'green', label = \"ReLuValidationAccuracy\")\n",
    "\n",
    "axs[0].set(ylabel = 'Accuracy')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Accuracy')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,5))\n",
    "\n",
    "\n",
    "axs[0].plot(lreluLrnAcc, color = 'orange', label = \"LeakyReLuTrainingAccuracy\")\n",
    "\n",
    "\n",
    "axs[1].plot(lreluValAcc, color = 'green', label = \"LeakyReLuValidationAccuracy\")\n",
    "\n",
    "axs[0].set(ylabel = 'Accuracy')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Accuracy')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sigmoid Function\")\n",
    "print()\n",
    "print(\"  Dataset   |   Loss | Accuracy\")\n",
    "print(\"  Training  | %.4f | %.4f\" % (sigmoidLrnLoss[-1], sigmoidLrnAcc[-1]))\n",
    "print(\" Validation | %.4f | %.4f\" % (sigmoidValLoss[-1], sigmoidValAcc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tanh Function\")\n",
    "print()\n",
    "print(\"  Dataset   |   Loss | Accuracy\")\n",
    "print(\"  Training  | %.4f | %.4f\" % (tanhLrnLoss[-1], tanhLrnAcc[-1]))\n",
    "print(\" Validation | %.4f | %.4f\" % (tanhValLoss[-1], tanhValAcc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ReLu Function\")\n",
    "print()\n",
    "print(\"  Dataset   |   Loss | Accuracy\")\n",
    "print(\"  Training  | %.4f | %.4f\" % (reluLrnLoss[-1], reluLrnAcc[-1]))\n",
    "print(\" Validation | %.4f | %.4f\" % (reluValLoss[-1], reluValAcc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Leaky ReLu Function\")\n",
    "print()\n",
    "print(\"  Dataset   |   Loss | Accuracy\")\n",
    "print(\"  Training  | %.4f | %.4f\" % (lreluLrnLoss[-1], lreluLrnAcc[-1]))\n",
    "print(\" Validation | %.4f | %.4f\" % (lreluValLoss[-1], lreluValAcc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%10s | %4s%3s%5s | %4s%3s%5s \" % (\"Dataset\", \"\", \"Max\", \"\", \"\", \"Min\",\"\"))\n",
    "print(\"%10s | %.10f | %.10f\" % (\"Sigmoid\", sigmoidMaxAcc, sigmoidMinLoss))\n",
    "print(\"%10s | %.10f | %.10f\" % (\"Tanh\", tanhMaxAcc, tanhMinLoss))\n",
    "print(\"%10s | %.10f | %.10f\" % (\"ReLu\", reluMaxAcc, reluMinLoss))\n",
    "print(\"%10s | %.10f | %.10f\" % (\"LRelu\", lreluMaxAcc, lreluMinLoss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
